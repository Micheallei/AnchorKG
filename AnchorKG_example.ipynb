{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository contains the source code of the paper: Reinforced Anchor Knowledge Graph Generation for News Recommendation Reasoning\n",
    "\n",
    "![framework](./framework.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./framework.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description and download\n",
    "\n",
    "MIND dataset [2] is a large-scale English news dataset. It was collected from anonymized behavior logs of Microsoft News website. MIND contains 1,000,000 users, 161,013 news articles and 15,777,377 impression logs. Every news article contains rich textual content including title, abstract, body, category and entities. Each impression log contains the click events, non-clicked events and historical news click behaviors of this user before this impression.\n",
    "\n",
    "For quicker training and evaluaiton, we sample MINDdemo dataset of 5k users from MIND small dataset. The MINDdemo dataset has the same file format as MINDsmall and MINDlarge. If you want to try experiments on MINDsmall and MINDlarge, please change the dowload source. Select the MIND_type parameter from ['large', 'small', 'demo'] to choose dataset.\n",
    "\n",
    "MINDdemo_train is used for training, and MINDdemo_dev is used for evaluation. Training data and evaluation data are composed of a news file and a behaviors file. You can find more detailed data description in [MIND repo](https://github.com/msnews/msnews.github.io/blob/master/assets/doc/introduction.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.util import *\n",
    "\n",
    "# Options: demo, small, large\n",
    "MIND_type = 'demo'\n",
    "data_path = \"./data/\"\n",
    "\n",
    "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
    "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
    "knowledge_graph_file = os.path.join(data_path, 'kg/wikidata-graph', r'wikidata-graph.tsv')\n",
    "entity_embedding_file = os.path.join(data_path, 'kg/wikidata-graph', r'entity2vaecd100.vec')\n",
    "relation_embedding_file = os.path.join(data_path, 'kg/wikidata-graph', r'relation2vecd100.vec')\n",
    "\n",
    "mind_url, mind_train_dataset, mind_dev_dataset, _ = get_mind_data_set(MIND_type)\n",
    "\n",
    "kg_url = \"https://kredkg.blob.core.windows.net/wikidatakg/\"\n",
    "\n",
    "if not os.path.exists(train_news_file):\n",
    "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
    "    \n",
    "if not os.path.exists(valid_news_file):\n",
    "    download_deeprec_resources(mind_url, \\\n",
    "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
    "\n",
    "if not os.path.exists(knowledge_graph_file):\n",
    "    download_deeprec_resources(kg_url, \\\n",
    "                               os.path.join(data_path, 'kg'), \"kg.zip\")a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('')\n",
    "\n",
    "import argparse\n",
    "from parse_config import ConfigParser\n",
    "\n",
    "parser = argparse.ArgumentParser(description='AnchorKG')\n",
    "\n",
    "\n",
    "parser.add_argument('-c', '--config', default=\"./config.json\", type=str,\n",
    "                    help='config file path (default: None)')\n",
    "parser.add_argument('-r', '--resume', default=None, type=str,\n",
    "                    help='path to latest checkpoint (default: None)')\n",
    "parser.add_argument('-d', '--device', default=None, type=str,\n",
    "                    help='indices of GPUs to enable (default: all)')\n",
    "\n",
    "config = ConfigParser.from_args(parser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "config['trainer']['epochs'] = epochs\n",
    "config['data_loader']['batch_size'] = batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process MIND dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing item2item dataset ... \n",
      "constructing news features ... \n"
     ]
    }
   ],
   "source": [
    "process_mind_data(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing train ...\n",
      "constructing val ...\n",
      "constructing test ...\n",
      "constructing doc feature embedding ...\n",
      "constructing adjacency matrix ...\n",
      "constructing kg env ...\n",
      "build neiborhood embedding ...\n",
      "constructing embedding ...\n",
      "constructing hit dict ...\n",
      "fininsh loading data!\n"
     ]
    }
   ],
   "source": [
    "data = load_data(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor graph training\n",
      "at epoch 1\n",
      "anchor all loss: 258.7453 \n",
      "embedding all loss: 1976.6974 \n",
      "reasoning all loss: 2116.8164 \n",
      "eval info: auc:0.6390\n",
      "at epoch 2\n",
      "anchor all loss: 183.7712 \n",
      "embedding all loss: 1771.4130 \n",
      "reasoning all loss: 2027.1009 \n",
      "eval info: auc:0.6706\n",
      "at epoch 3\n",
      "anchor all loss: 161.0648 \n",
      "embedding all loss: 1687.2168 \n",
      "reasoning all loss: 1977.3318 \n",
      "eval info: auc:0.6855\n",
      "at epoch 4\n",
      "anchor all loss: 155.2929 \n",
      "embedding all loss: 1636.4263 \n",
      "reasoning all loss: 1939.5623 \n",
      "eval info: auc:0.6903\n",
      "at epoch 5\n",
      "anchor all loss: 149.8370 \n",
      "embedding all loss: 1602.0648 \n",
      "reasoning all loss: 1905.3371 \n",
      "eval info: auc:0.6930\n",
      "NDCG=5.706 |  Recall=10.23 | HR=13.41 | Precision=1.596\n"
     ]
    }
   ],
   "source": [
    "train(data, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG=5.706 |  Recall=10.23 | HR=13.41 | Precision=1.596\n"
     ]
    }
   ],
   "source": [
    "test_data = data[4]\n",
    "testing(test_data, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on MINDlarge\n",
    "\n",
    "We test the performance on MINDlarge dataset for your reference, note that the publish dataset doesn't contain the testdata and only have title and abstract, in the papaer, we used all the data and used title, abstract and body.\n",
    "\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Wu, Fangzhao, et al. \"MIND: A Large-scale Dataset for News Recommendation\" Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('RecStudio': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d07159e004763d7de8c8f99c522b67ee8903d5beb6f9577c631266fffbbd3be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
